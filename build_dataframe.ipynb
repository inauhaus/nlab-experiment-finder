{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c57a79",
   "metadata": {},
   "source": [
    "# Building a Pandas data frame from Matlab experiment files in the Nauhaus lab.\n",
    "\n",
    "This code builds a huge table, where each row is a different experiment, and each column is an experimental variable. The information is extracted from the .analyzer files, typical contained in the folder 'AnalyzerFiles'. A given 'AnalyzerFiles' folder will have experimental information associated with potentially every experiment ever performed in the Nauhaus Lab. At a minimum, the information related to each experiment is contained in the GUIs on the stimulus controller: e.g. animal name, screen distance, visual stimulus looping parameters, parameter lists, display type, recording method, etc. \n",
    "\n",
    "The table that gets built is in the form of a Pandas data frame. Pandas is an analysis tool built on Python. This allows for a ton of flexibility for filtering out different experiments. Examples are given at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "623e22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from organizemat import organizemat #Local. Taken from S.O.\n",
    "from mat2list import mat2list #My function. Interprets MATLAB vector into a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a324146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no animals =  605\n"
     ]
    }
   ],
   "source": [
    "#type in the path location of this notebook\n",
    "wdir = '/Users/in2293/Desktop/nlab_experiment_finder' #working directory\n",
    "os.chdir(wdir)\n",
    "\n",
    "#Analyzer files may be somewhere else on th eocmputer...\n",
    "fileloc = '/Users/in2293/Desktop/Desktop/AnalyzerFiles' \n",
    "\n",
    "subfolders = [f.path for f in os.scandir(fileloc) if f.is_dir() ] #list of all the folder names\n",
    "print('no animals = ', len(subfolders))  #Each folder is a separate animal.\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None) #Show all columns of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e7d02",
   "metadata": {},
   "source": [
    "# Build or load the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f3f80",
   "metadata": {},
   "source": [
    "# Build it...\n",
    "The cell below takes about ~15 min to run. It loads every analyzer file and accumulates to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc75ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Initialize the 3 data frames. We will append 1 row of data after loading each experiment\n",
    "ACQcolumns = ['FPS', 'bin', 'timecourseBit', 'btwTrialShutter', 'MechbtwTrialShutter',\n",
    "                'ROIcrop', 'sensorGain','Gamma', 'camera', 'chipSIZE']\n",
    "Mdf = pd.DataFrame()\n",
    "Pdf = pd.DataFrame()\n",
    "Ldf = pd.DataFrame()\n",
    "ACQdf = pd.DataFrame(columns = ACQcolumns)\n",
    "\n",
    "\n",
    "unloaded_experiments = []\n",
    "\n",
    "exp_count = 0;\n",
    "\n",
    "\n",
    "for fi,f in enumerate(subfolders):  #loop each animal\n",
    "    \n",
    "      print(f)\n",
    "        \n",
    "      for anafile in os.scandir(f):  #loop each experiment from the given animal\n",
    "        try:\n",
    "            \n",
    "            data = io.loadmat(anafile.path, struct_as_record=False, squeeze_me=True)\n",
    "            \n",
    "            #Other things I tried for loading MATLAB .mat file and the reasons they didn't work:\n",
    "            #Analyzer = loadmat(anafile.path)  #Could use this instead of the above, but it takes too long.          \n",
    "            #Analyzer = io.loadmat(anafile.path,simplify_cells = True) #Throws error for files containing video object\n",
    "            \n",
    "        except:  #Sometimes there are irrelevant files saved in each folder. \n",
    "                #I want to make sure they are irrelevant by storing their name.\n",
    "            \n",
    "            print('error loading ', anafile.path)    \n",
    "            unloaded_experiments.append(anafile.path) #I want to know what files were not loaded\n",
    "            continue\n",
    "                \n",
    "        #Remove unnecessary \"syncInfo\". \n",
    "        #Otherwise it takes forever to parse into a dict below.\n",
    "        data_copy = data.copy()\n",
    "        for k,v in data.items():\n",
    "            if k[0:4] == 'sync':        \n",
    "                data_copy.pop(k)\n",
    "\n",
    "        #Organize loaded .mat file into something readable.  Ref: StackOverflow.\n",
    "        Analyzer = organizemat(data_copy)   \n",
    "        \n",
    "        #Move header into the M dict\n",
    "        header = Analyzer['__header__']\n",
    "        try: #I found some analyzer files that were missing 'Analyzer', but had 'f1m' wtf???\n",
    "            Analyzer = Analyzer['Analyzer']\n",
    "        except:\n",
    "            continue\n",
    "        Analyzer['M']['header'] = header   \n",
    "        \n",
    "        #Experimental parameters are in 3 GUI windows at stimulus-controller:\n",
    "        M = Analyzer['M'].copy() #Parameters in the \"MW\" GUI\n",
    "        L = Analyzer['L'].copy() #Parameters in the \"Looper\" GUI\n",
    "        P = Analyzer['P'].copy() #Parameters in the \"paramList\" GUI\n",
    "        \n",
    "        #Reformat ACQ\n",
    "        if 'ACQ' in Analyzer: #Only widefield experiments have ACQ.  And some really old WF do not either.\n",
    "            ACQ = dict(zip(ACQcolumns, [None]*len(ACQcolumns)))\n",
    "            for i in ACQcolumns:\n",
    "                if i in Analyzer['ACQ']:\n",
    "                    ACQ[i] = Analyzer['ACQ'][i]\n",
    "                \n",
    "            for k,v in ACQ.items():\n",
    "                if type(v) != float and type(v) != int:\n",
    "                    ACQ[k] = str(v)\n",
    "\n",
    "        #Reformat L\n",
    "        if type(L['param'][0]) is str: #Asks if there is only one looping parameter\n",
    "            L['param'] = [L['param']]  #Embed it to make it consistent with N>1 parameter case         \n",
    "        n_loop_param = len(L['param'])  #number of looping parameters\n",
    "        #mat2list converts a matlab vector creation (e.g. '0:45:315', or [0 45]), into a complete Python list.\n",
    "        #Expanding the vector into a Python list allows for easier querying of the data frame.\n",
    "        for i in range(n_loop_param):\n",
    "            L['paramSymbol' + str(i+1)] = L['param'][i][0]\n",
    "            L['paramValues' + str(i+1)] = str(mat2list(L['param'][i][1]))\n",
    "            \n",
    "            L['paramValuesMatlabStr' + str(i+1)] = L['param'][i][1]\n",
    "        \n",
    "        L.pop('param') #No longer needed. Redundant.\n",
    "        \n",
    "        #json_normalize turns it into a df, and helps to unpack some fields\n",
    "        M = pd.json_normalize(M)\n",
    "        L = pd.json_normalize(L)\n",
    "        P = pd.json_normalize(P)\n",
    "        if 'ACQ' in Analyzer:\n",
    "            ACQ = pd.json_normalize(ACQ)\n",
    "        \n",
    "        #Reformat P data frame:\n",
    "        #Create a data frame with one row: columns are the parameter symbols, entries are the values.\n",
    "        columns = list(pd.DataFrame(P.param[0]).iloc[:,0]) #columns\n",
    "        values = list(pd.DataFrame(P.param[0]).iloc[:,2]) #values\n",
    "        columns = ['module'] + columns  #Add a new first element to the list\n",
    "        values = [P.type[0]] + values  #append front with module: e.g. 'PG' for periodic grater\n",
    "        P = pd.DataFrame(columns = columns)\n",
    "        P.loc[0] = values \n",
    "     \n",
    "        Mdf = Mdf.append(M,ignore_index = True)\n",
    "        Ldf = Ldf.append(L,ignore_index = True)\n",
    "        Pdf = Pdf.append(P,ignore_index = True)\n",
    "        ACQdf = ACQdf.append(ACQ,ignore_index = True)\n",
    "        \n",
    "        exp_count += 1\n",
    "        \n",
    "\n",
    "Mdf.drop(columns = ['camera'],axis = 1,inplace = True) #This field is usually wrong, and redundant with ACQ.camera.        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5dd588",
   "metadata": {},
   "source": [
    "# Clean up and save the table as a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6e11e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved table with 7226 experiments to  /Users/in2293/Desktop/nlab_experiment_finder\n"
     ]
    }
   ],
   "source": [
    "print(exp_count)\n",
    "print(Mdf.shape, Ldf.shape, Pdf.shape, ACQdf.shape)\n",
    "print(exp_count)\n",
    "\n",
    "#This requires something different for queries, which I have not yet figured out:\n",
    "#df = pd.concat([Mdf,Ldf,Pdf,ACQdf],keys=['M', 'L', 'P', 'ACQ'],axis = 1)    #Create one single data frame with all the parameters.\n",
    "\n",
    "df = pd.concat([Mdf,Ldf,Pdf,ACQdf],axis = 1)    #Create one single data frame with all the parameters.\n",
    "df = df.drop_duplicates(subset=['anim', 'expt','WF']) #Remove redundant rows: copies of a file often exist.\n",
    "\n",
    "df.to_csv('all_experiments') #saves to working dir\n",
    "\n",
    "print(f'saved table with {df.shape[0]} experiments to ', wdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4cf8c",
   "metadata": {},
   "source": [
    "# Load saved table\n",
    "\n",
    "This is an alternative to the 'load' and 'save cells above.  You don't need the .analyzer files for this, only the saved .csv file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "46212f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/in2293/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (2,29,68) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('all_experiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61239c",
   "metadata": {},
   "source": [
    "# Example: Create a table that only contains widefield Kalatsky retinotopy experiments.\n",
    "\n",
    "Kalatsky experiments have some unique features. \n",
    "1) The looper only has ori = [0 90 180 270] \\\n",
    "2) The temporal period is really long.  e.g. > 800 frames. \\\n",
    "The above should narrow it down, but I include several other dependencies as well, just to make sure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cee393cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 2148 experiments where ori is only looping variable: [0 90 180 270]\n",
      "n = 1716\n",
      "n = 1716\n",
      "n = 1594\n",
      "n = 1591\n",
      "n = 1591 Kalatsky experiments\n",
      "n = 1309 widefield Kalatsky experiments\n"
     ]
    }
   ],
   "source": [
    "#Find all experiments where orientation was the only looping variable\n",
    "\n",
    "#Make sure ori is the only looping parameter\n",
    "Kdf = df.query(\"paramSymbol1 == 'ori'\"). \\\n",
    "            query('paramSymbol2 != paramSymbol2'). \\\n",
    "            query('paramSymbol2 != paramSymbol3'). \\\n",
    "            query('paramSymbol3 != paramSymbol4') \n",
    "            \n",
    "\n",
    "#ori loops through for cardinal directions: \n",
    "Kdf = Kdf.query(\"paramValues1 == '[0.0, 90.0, 180.0, 270.0]'\")\n",
    "    \n",
    "print(f'n = {Kdf.shape[0]} experiments where ori is only looping variable: [0 90 180 270]')\n",
    "\n",
    "#The bar is changing slowly\n",
    "Kdf = Kdf.query('t_period > 800')\n",
    "print(f'n = {Kdf.shape[0]}')\n",
    "\n",
    "#The bar is drifting\n",
    "Kdf = Kdf.query('separable == 0')\n",
    "print(f'n = {Kdf.shape[0]}')\n",
    "\n",
    "#The bar drifts over a large part of the screen\n",
    "Kdf = Kdf.query('x_size > 100').query('y_size > 100')\n",
    "print(f'n = {Kdf.shape[0]}')\n",
    "      \n",
    "#There is only one bar on the screen\n",
    "Kdf = Kdf.query('s_freq < 1/80')\n",
    "print(f'n = {Kdf.shape[0]}')\n",
    "\n",
    "#Its a narrow bar and not a sinewave\n",
    "Kdf = Kdf.query(\"st_profile == 'square'\").query(\"s_duty < 0.4\")\n",
    "print(f'n = {Kdf.shape[0]} Kalatsky experiments')\n",
    "\n",
    "\n",
    "Kdf = Kdf.query(\"WF == 1\")  #Change this to 'twoP' if you want two-photon Kalatsky\n",
    "print(f'n = {Kdf.shape[0]} widefield Kalatsky experiments')\n",
    "\n",
    "#Kdf = Kdf.drop_duplicates(subset = ['anim'])\n",
    "#print(f'n = {Kdf.shape[0]} animals in which widefield Kalatsky was run')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27f474",
   "metadata": {},
   "source": [
    "# Save table of Kalatsky experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "10f4f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved table with 1309 experiments to  /Users/in2293/Desktop/nlab_experiment_finder\n"
     ]
    }
   ],
   "source": [
    "Kdf.to_csv('Kalatsky table') #saves to working dir\n",
    "\n",
    "print(f'saved table with {Kdf.shape[0]} experiments to ', wdir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
